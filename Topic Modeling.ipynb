{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Libraries",
   "id": "8076c792d25750f4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-13T06:57:52.492010Z",
     "start_time": "2025-07-13T06:57:48.662068Z"
    }
   },
   "source": [
    "from nest_asyncio import apply\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from hazm import Normalizer, word_tokenize, stopwords_list\n",
    "import  pandas as pd\n",
    "import re\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from sqlalchemy import create_engine, text\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Getting Data from Database ",
   "id": "34efd745c0ba8b28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:02:30.434101Z",
     "start_time": "2025-07-13T07:02:29.795189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# user = 'user'\n",
    "# password = 'password'\n",
    "# host = 'host'\n",
    "# port = 'port'\n",
    "# service_name ='srvice_name'\n",
    "# \n",
    "# dsn = f'oracle+oracledb://{user}:{password}@{host}:{port}/?service_name={service_name}'\n",
    "# engine = create_engine(dsn)\n",
    "# \n",
    "# sql_transaction_image = f\"\"\"\n",
    "#     SELECT ti.ID ,ti.OCR_TEXT ,t.TERMINAL_ID1\n",
    "#     FROM \"TRANSACTION\" t \n",
    "#     JOIN TRANSACTION_IMAGE ti ON t.ID = ti.TRANSACTION_ID \n",
    "#     JOIN TERMINAL t2 ON t2.ID = t.TERMINAL_ID1 \n",
    "#     JOIN MERCHANT m ON m.ID = t2.MERCHANT_ID \n",
    "#     WHERE   ti.TYPE_ID IN (1,2) AND ti.OCR_TEXT IS NOT NULL AND m.STATUS != 'V' \n",
    "#     ORDER BY ti.ID ASC\n",
    "# \"\"\"\n",
    "# with engine.connect() as conn:\n",
    "#     dataset_main = pd.read_sql(sql=sql_transaction_image, con=conn)\n"
   ],
   "id": "fc1ac7a332578bb1",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m service_name \u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msrvice_name\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      7\u001B[0m dsn \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moracle+oracledb://\u001B[39m\u001B[38;5;132;01m{\u001B[39;00muser\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpassword\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhost\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mport\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/?service_name=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mservice_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 8\u001B[0m engine \u001B[38;5;241m=\u001B[39m create_engine(dsn)\n\u001B[0;32m     10\u001B[0m sql_transaction_image \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;124m    SELECT ti.ID ,ti.OCR_TEXT ,t.TERMINAL_ID1\u001B[39m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124m    FROM \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTRANSACTION\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m t \u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124m    ORDER BY ti.ID ASC\u001B[39m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m engine\u001B[38;5;241m.\u001B[39mconnect() \u001B[38;5;28;01mas\u001B[39;00m conn:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'create_engine' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T06:58:18.856621Z",
     "start_time": "2025-07-13T06:58:02.254568Z"
    }
   },
   "cell_type": "code",
   "source": "df=pd.read_csv(r\"C:\\Users\\s.heydarian\\Desktop\\dashboard data\\TRANSACTION_DESCRIPTION_202507071458.csv\")",
   "id": "ee4b4503f8f4805f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data cleaning",
   "id": "9990c7c86a218675"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.drop_duplicates(inplace=True)",
   "id": "a1cff8ebd27af423"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def remove_all_numbers(text):\n",
    "    return re.sub(r'[0-9۰-۹]', '', text)"
   ],
   "id": "94d08cc65f98fe1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = df[~df[\"NAME\"].str.isdigit()]",
   "id": "68ac3490b902bed2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def remove_all_english(text):\n",
    "    return re.sub(r'[a-zA-z]', ''  , text)"
   ],
   "id": "4578c1be0897c578"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def remove_emojis_and_symbols(text):\n",
    "    emoji_symbol_pattern = re.compile(\"[\"\n",
    "                                      u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                                      u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "                                      u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "                                      u\"\\U0001F700-\\U0001F77F\"  # Alphanumeric & geometric shapes\n",
    "                                      u\"\\U0001F780-\\U0001F7FF\"  # Geometric shapes extended\n",
    "                                      u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                                      u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                                      u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                                      u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                                      u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                                      u\"\\U000024C2-\\U0001F251\" \n",
    "                                      r\"\\W\"  # Non-word characters (symbols)\n",
    "                                      \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    clean_text = re.sub(emoji_symbol_pattern, ' ', text)\n",
    "\n",
    "    return clean_text"
   ],
   "id": "cd737c3b23e8bcdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['name']=df['name'].apply(remove_emojis_and_symbols)",
   "id": "75fe8d65e42f240e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['name']=df['name'].apply(remove_all_english)",
   "id": "f0f1d9c64df7931"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['name']=df['name'].apply(remove_all_numbers)\n",
   "id": "6d31e1fc7c3a1680"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['name'] = (\n",
    "    df['name']\n",
    "    .str.replace(r'[\"\\r\\n]', '', regex=True)      # Remove quotes, carriage return, newlines\n",
    "    .str.replace(r',,', '', regex=True)           # Remove double commas\n",
    "    .str.replace(r'\\s+', ' ', regex=True)         # Collapse multiple spaces\n",
    "    .str.strip()                                  # Remove leading/trailing whitespace\n",
    ")"
   ],
   "id": "61b6f410319b00ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = df[df['DESCRIPTION'].str.strip() != '']",
   "id": "5b19bc4d0348f6fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "db99cdc8163400a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Persian stopwords\n",
    "\n",
    "custom_stopwords  = {\"کد\", \"جهت\",\"برداشت\", \"کارت\", \"مبلغ\", \"توسط\" ,  \"شماره\",  \"بمبلغ\", \"رهگيري\" ,  \"بانک\", \"مهرايران\", \"ما\" ,  \"جغطائی\", \"الحسنه\" , \"مدرن\", \"الحسنه\", \"رهگیری\" , \"الحسنه\", \"قرض\"}\n",
    "\n",
    "all_stopwords = set(stopwords_list()).union(custom_stopwords)\n",
    "\n",
    "normalizer = Normalizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = normalizer.normalize(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in all_stopwords and len(t) > 1]\n",
    "    return ' '.join(tokens)  # For TF-IDF, we need a string\n"
   ],
   "id": "f5e19420b28dfe40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['name'] = df['name'].apply(preprocess)",
   "id": "d39712e27451320a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=10, max_df=0.75)\n",
    "doc_term_matrix = tfidf_vectorizer.fit_transform(df['name'])\n",
    "\n",
    "print(f\"TF-IDF Matrix: {doc_term_matrix.shape}\")\n"
   ],
   "id": "de0dc53ab7dfc364"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_topics = 5\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "doc_topic_matrix = lda.fit_transform(doc_term_matrix)\n",
    "\n",
    "topic_names = [f\"Topic {i+1}\" for i in range(num_topics)]\n",
    "doc_topic_df = pd.DataFrame(doc_topic_matrix, columns=topic_names)\n",
    "print(doc_topic_df.head())"
   ],
   "id": "83a7e5b0c1edb3d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_words = 10\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()"
   ],
   "id": "5470126c9b402b67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"\\n Topic {topic_idx + 1}\")\n",
    "    top_indices = topic.argsort()[::-1][:num_words]\n",
    "    for i in top_indices:\n",
    "        print(f\"   {feature_names[i]} ({topic[i]:.3f})\")"
   ],
   "id": "6aab774137f1da9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ========== Step 7: Perplexity vs. Topic Count ==========\n",
    "perplexities = []\n",
    "topic_counts = range(2, 11)\n",
    "\n",
    "for k in topic_counts:\n",
    "    lda_k = LatentDirichletAllocation(n_components=k, random_state=42)\n",
    "    lda_k.fit(doc_term_matrix)\n",
    "    perp = lda_k.perplexity(doc_term_matrix)\n",
    "    perplexities.append(perp)\n",
    "\n",
    "# ========== Step 8: Plot Perplexity ==========\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(x=topic_counts, y=perplexities, marker='o')\n",
    "plt.title('Perplexity by Topic Count')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "faa349f7808d9440"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
